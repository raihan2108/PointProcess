{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sathappan/workspace/time2event/src\n"
     ]
    }
   ],
   "source": [
    "cd /home/sathappan/workspace/time2event/src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PointProcess.hawkes import UniVariateHawkes\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from datetime import timedelta\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"/home/sathappan/user_timeseries_sorted.gz\" ) as inf:\n",
    "    cnt = 0\n",
    "    d2 = []\n",
    "    import json\n",
    "    from dateutil.parser import parse\n",
    "    for i in inf:\n",
    "        d2.append([parse(dt) for dt in json.loads(i)['arrivalTimes']])\n",
    "        cnt += 1\n",
    "        if cnt > 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = pd.DataFrame(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe.columns = [str(l) for l in range(0, 1540)]\n",
    "names = [str(l) for l in range(0, 1540)]\n",
    "#df['newcol'] = df[['col1','col2']].sum(axis=1) - df['col5']\n",
    "#df[['newcol', 'col3']].sub(df['col5'], axis=0)\n",
    "arrivals = dframe[names[:400]].sub(dframe[\"0\"], axis=0)\n",
    "mask = ~(arrivals.isnull()).as_matrix()\n",
    "arrivals_numpy = np.nan_to_num(arrivals.applymap(lambda x: x/np.timedelta64(1, '1D')).as_matrix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Ai(arrivals, mask, beta):\n",
    "    tdiff = np.diff(arrivals) * mask[:, 1:]\n",
    "    tdiff = np.exp(tdiff * -beta)\n",
    "    A_i = np.zeros_like(arrivals, dtype=np.float128)\n",
    "    for i in range(tdiff.shape[1]):\n",
    "        #print(i,)\n",
    "        A_i[:, i + 1] = tdiff[:, i] * (1 + A_i[:, i])\n",
    "    return A_i, tdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_i, tempdiff = calc_Ai(arrivals_numpy, mask, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood():\n",
    "    #tdiff = diff(arrivals) * mask[:, 1:]\n",
    "    #A_i = tf.zeros_like(arrivals)\n",
    "    #for i in range(tdiff.shape[0]):\n",
    "    #    A_i[:, i + 1] = tdiff[:, i] * (1 + A[:, i ])\n",
    "    part1 = tf.reduce_sum(tf.log(mu + alpha * ais_tvar), axis=1)[:, None]\n",
    "    T_max = tf.reduce_max(arrivals_tvar*mask_tvar, axis=1)[:, None]\n",
    "    part2 = mu * T_max\n",
    "    p3_tmp = tf.reduce_sum(tf.exp(-beta * ((T_max - arrivals_tvar)*mask_tvar)) - tf.constant(1.0, dtype=tf.float64), axis=1)\n",
    "    part3 = (alpha / beta)* p3_tmp[:, None]\n",
    "    \n",
    "    #return part1, part2, part3, p3_tmp\n",
    "    return -1*tf.reduce_sum(part1 - part2 + part3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assuming number of users is 32\n",
    "num_users = 101\n",
    "\n",
    "## All parameters are column vectors with size equal to number of users\n",
    "\n",
    "alpha = tf.Variable(tf.ones([num_users, 1], dtype=tf.float64), dtype=tf.float64)\n",
    "beta = tf.Variable(tf.ones([num_users, 1], dtype=tf.float64), dtype=tf.float64)\n",
    "mu = tf.Variable(tf.ones([num_users, 1], dtype=tf.float64), dtype=tf.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_max = 400\n",
    "arrivals_tvar = tf.placeholder(tf.float64, [None, T_max])\n",
    "mask_tvar = tf.placeholder(tf.float64, [None, T_max])\n",
    "ais_tvar = tf.placeholder(tf.float64,[None, T_max])\n",
    "tdiff_tvar = tf.placeholder(tf.float64, [None, T_max-1])\n",
    "p3 = loglikelihood()\n",
    "grad = tf.gradients(p3, [alpha, beta, mu])\n",
    "optim = tf.train.GradientDescentOptimizer(0.01).minimize(p3)\n",
    "#p1, p2, p3 = loglikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tf_a = (sess.run([p3, optim], feed_dict={arrivals_tvar: np.nan_to_num(arrivals_numpy), mask_tvar:mask, ais_tvar:A_i, tdiff_tvar: tempdiff}))\n",
    "    #tf_a, tf_b, tf_c, tf_d = (sess.run(p3, feed_dict={arrivals_tvar: np.nan_to_num(arrivals_numpy), mask_tvar:mask, ais_tvar:A_i, tdiff_tvar: tempdiff}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40826.057238954279, None]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-57.18139879])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_a[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-40826.057238954279"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf_a[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
